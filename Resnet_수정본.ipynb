{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hun9008/ML_TeamProject_24SS/blob/main/Resnet_%EC%88%98%EC%A0%95%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaQi2LTwPNco",
        "outputId": "bb3eef3b-9cb3-4e7b-ad51-43af0e3bcd0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/ML_TeamProject/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O_T_aU6PdD1",
        "outputId": "72bc8575-d424-4d79-ea17-d3856703a768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML_TeamProject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3zfoxPtPjlS",
        "outputId": "e08a3bdf-8217-475d-d481-ffbd96dcf4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/             \u001b[01;34mimages_png\u001b[0m/                                        VGG.ipynb\n",
            "\u001b[01;34mimages_gray_jpg\u001b[0m/  \u001b[01;34mpreprocessed_images_40\u001b[0m/                            \u001b[01;34m무_train_labeled_2000\u001b[0m/\n",
            "\u001b[01;34mimages_gray_png\u001b[0m/  PreTest.ipynb\n",
            "\u001b[01;34mimages_jpg\u001b[0m/       vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import pickle\n",
        "import optuna\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE16NJ5TPlN_",
        "outputId": "dbec89e0-25c6-4e23-9765-a9010d19c572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_jpg_path = \"/content/drive/My Drive/ML_TeamProject/images_jpg\"\n",
        "image_png_path = \"/content/drive/My Drive/ML_TeamProject/images_png\"\n",
        "image_gray_jpg_path = \"/content/drive/My Drive/ML_TeamProject/images_gray_jpg\"\n",
        "image_gray_png_path = \"/content/drive/My Drive/ML_TeamProject/images_gray_png\""
      ],
      "metadata": {
        "id": "34-qwn4kPr92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image JPG"
      ],
      "metadata": {
        "id": "SQJv_G7ag6uC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(image_jpg_path)"
      ],
      "metadata": {
        "id": "kou4BAY0fgPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 모든 폴더에서 zero_centering.pkl 파일을 읽어옴\n",
        "data = {}\n",
        "folders = ['incipient', 'mature', 'no', 'overripe']\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join('path_to_folders', folder)  # 각 폴더의 경로\n",
        "    file_path = os.path.join(folder_path, 'zero_centering.pkl')\n",
        "    with open(file_path, 'rb') as f:\n",
        "        folder_data = pickle.load(f)\n",
        "        data.update(folder_data)\n",
        "\n",
        "# 데이터 전처리\n",
        "X = np.array(list(data.values()))\n",
        "y = np.array([label['stage'] for label in data.keys()])\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ResNet 모델 생성\n",
        "base_model = ResNet50(include_top=False, input_shape=X_train[0].shape)\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료 콜백 설정\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'image_jpg Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "id": "S6YmnXTgfIr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image PNG"
      ],
      "metadata": {
        "id": "cPgENs1IhROq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(image_png_path)"
      ],
      "metadata": {
        "id": "J8yKA02PhHds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 모든 폴더에서 zero_centering.pkl 파일을 읽어옴\n",
        "data = {}\n",
        "folders = ['incipient', 'mature', 'no', 'overripe']\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join('path_to_folders', folder)  # 각 폴더의 경로\n",
        "    file_path = os.path.join(folder_path, 'zero_centering.pkl')\n",
        "    with open(file_path, 'rb') as f:\n",
        "        folder_data = pickle.load(f)\n",
        "        data.update(folder_data)\n",
        "\n",
        "# 데이터 전처리\n",
        "X = np.array(list(data.values()))\n",
        "y = np.array([label['stage'] for label in data.keys()])\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ResNet 모델 생성\n",
        "base_model = ResNet50(include_top=False, input_shape=X_train[0].shape)\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료 콜백 설정\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'image_png Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "id": "xa6BS4YIhPUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image GRAY JPG"
      ],
      "metadata": {
        "id": "AhoOgSowhTiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(image_gray_jpg_path)"
      ],
      "metadata": {
        "id": "abRSA53HhXeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 모든 폴더에서 zero_centering.pkl 파일을 읽어옴\n",
        "data = {}\n",
        "folders = ['incipient', 'mature', 'no', 'overripe']\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join('path_to_folders', folder)  # 각 폴더의 경로\n",
        "    file_path = os.path.join(folder_path, 'zero_centering.pkl')\n",
        "    with open(file_path, 'rb') as f:\n",
        "        folder_data = pickle.load(f)\n",
        "        data.update(folder_data)\n",
        "\n",
        "# 데이터 전처리\n",
        "X = np.array(list(data.values()))\n",
        "y = np.array([label['stage'] for label in data.keys()])\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ResNet 모델 생성\n",
        "base_model = ResNet50(include_top=False, input_shape=X_train[0].shape)\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료 콜백 설정\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'image_gray_jpg Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "id": "Q3KPIHrqhbAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image GRAY PNG"
      ],
      "metadata": {
        "id": "49yXrOLPhcVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(image_gray_png_path)"
      ],
      "metadata": {
        "id": "HzAk0oV7hrMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 모든 폴더에서 zero_centering.pkl 파일을 읽어옴\n",
        "data = {}\n",
        "folders = ['incipient', 'mature', 'no', 'overripe']\n",
        "for folder in folders:\n",
        "    folder_path = os.path.join('path_to_folders', folder)  # 각 폴더의 경로\n",
        "    file_path = os.path.join(folder_path, 'zero_centering.pkl')\n",
        "    with open(file_path, 'rb') as f:\n",
        "        folder_data = pickle.load(f)\n",
        "        data.update(folder_data)\n",
        "\n",
        "# 데이터 전처리\n",
        "X = np.array(list(data.values()))\n",
        "y = np.array([label['stage'] for label in data.keys()])\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# ResNet 모델 생성\n",
        "base_model = ResNet50(include_top=False, input_shape=X_train[0].shape)\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 조기 종료 콜백 설정\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'image_gray_png Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "id": "b2DDWhnDhgPZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}