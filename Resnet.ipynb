{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPJZ5rIh77HJVKO60rglBnB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hun9008/ML_TeamProject_24SS/blob/main/Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PiAO58CWJpQ",
        "outputId": "2168c050-6849-4286-ab84-9098a1ff7620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IVPvuemdEFw",
        "outputId": "43df71b5-c098-4835-be20-968513a74971"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n"
      ],
      "metadata": {
        "id": "VympD2V5qPEo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/MLteamproject/\"\n",
        "folders = ['images_gray_png', 'images_gray_jpg', 'images_png', 'images_jpg']\n",
        "labels = ['mature', 'overripe', 'incipient', 'no']"
      ],
      "metadata": {
        "id": "bpMRHA6MqRn7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install zipfile36"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1rJl-3wXPrv",
        "outputId": "affe1b2f-09cf-4935-d2c0-5991c1a3225a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: zipfile36 in /usr/local/lib/python3.10/dist-packages (0.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip 파일들 unzip\n",
        "for folder in folders:\n",
        "    zip_path = os.path.join(image_path, folder, f'{folder}.zip')\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(os.path.join(image_path, folder))"
      ],
      "metadata": {
        "id": "w2Tq3vzpY3AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/MLteamproject/"
      ],
      "metadata": {
        "id": "nqJEWsoxIPIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rh3TAUQXUJoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## images_gray_jpg 관련 학습"
      ],
      "metadata": {
        "id": "INHHDnc_HVFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 경로 설정\n",
        "data_dir = 'images_gray_jpg'\n",
        "labels = ['incipient', 'mature', 'no', 'overripe']\n",
        "batch_size = 32\n",
        "\n",
        "# 이미지 파일 경로 수집\n",
        "image_paths = []\n",
        "for label in labels:\n",
        "    label_dir = os.path.join(data_dir, label)\n",
        "    image_paths += [os.path.join(label_dir, file) for file in os.listdir(label_dir)]\n",
        "\n",
        "# 라벨링\n",
        "labels_one_hot = np.zeros((len(image_paths), len(labels)))\n",
        "for i, path in enumerate(image_paths):\n",
        "    for j, label in enumerate(labels):\n",
        "        if label in path:\n",
        "            labels_one_hot[i][j] = 1\n",
        "\n",
        "# 데이터 분할\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels_one_hot, test_size=0.3, random_state=42)\n",
        "\n",
        "# ResNet50 모델 생성\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(labels), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 미세 조정 (Fine-tuning) 설정\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    train_paths,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(test_paths, test_labels)\n",
        ")\n",
        "\n",
        "# 시각화를 통한 정확도 및 손실도 확인\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_paths, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "4q1PgjwmHSml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## images_gray_png 학습"
      ],
      "metadata": {
        "id": "Lu6BpY2fUOoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 경로 설정\n",
        "data_dir = 'images_gray_png'\n",
        "labels = ['incipient', 'mature', 'no', 'overripe']\n",
        "batch_size = 32\n",
        "\n",
        "# 이미지 파일 경로 수집\n",
        "image_paths = []\n",
        "for label in labels:\n",
        "    label_dir = os.path.join(data_dir, label)\n",
        "    image_paths += [os.path.join(label_dir, file) for file in os.listdir(label_dir)]\n",
        "\n",
        "# 라벨링\n",
        "labels_one_hot = np.zeros((len(image_paths), len(labels)))\n",
        "for i, path in enumerate(image_paths):\n",
        "    for j, label in enumerate(labels):\n",
        "        if label in path:\n",
        "            labels_one_hot[i][j] = 1\n",
        "\n",
        "# 데이터 분할\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels_one_hot, test_size=0.3, random_state=42)\n",
        "\n",
        "# ResNet50 모델 생성\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(labels), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 미세 조정 (Fine-tuning) 설정\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    train_paths,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(test_paths, test_labels)\n",
        ")\n",
        "\n",
        "# 시각화를 통한 정확도 및 손실도 확인\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_paths, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "z8pOk3_nUK9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## images_png 학습"
      ],
      "metadata": {
        "id": "RKzNHkqRUjWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 경로 설정\n",
        "data_dir = 'images_png'\n",
        "labels = ['incipient', 'mature', 'no', 'overripe']\n",
        "batch_size = 32\n",
        "\n",
        "# 이미지 파일 경로 수집\n",
        "image_paths = []\n",
        "for label in labels:\n",
        "    label_dir = os.path.join(data_dir, label)\n",
        "    image_paths += [os.path.join(label_dir, file) for file in os.listdir(label_dir)]\n",
        "\n",
        "# 라벨링\n",
        "labels_one_hot = np.zeros((len(image_paths), len(labels)))\n",
        "for i, path in enumerate(image_paths):\n",
        "    for j, label in enumerate(labels):\n",
        "        if label in path:\n",
        "            labels_one_hot[i][j] = 1\n",
        "\n",
        "# 데이터 분할\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels_one_hot, test_size=0.3, random_state=42)\n",
        "\n",
        "# ResNet50 모델 생성\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(labels), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 미세 조정 (Fine-tuning) 설정\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    train_paths,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(test_paths, test_labels)\n",
        ")\n",
        "\n",
        "# 시각화를 통한 정확도 및 손실도 확인\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_paths, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "Qhu-DQD3UdFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## images_png 학습"
      ],
      "metadata": {
        "id": "DgAwY-xDUnOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 경로 설정\n",
        "data_dir = 'images_png'\n",
        "labels = ['incipient', 'mature', 'no', 'overripe']\n",
        "batch_size = 32\n",
        "\n",
        "# 이미지 파일 경로 수집\n",
        "image_paths = []\n",
        "for label in labels:\n",
        "    label_dir = os.path.join(data_dir, label)\n",
        "    image_paths += [os.path.join(label_dir, file) for file in os.listdir(label_dir)]\n",
        "\n",
        "# 라벨링\n",
        "labels_one_hot = np.zeros((len(image_paths), len(labels)))\n",
        "for i, path in enumerate(image_paths):\n",
        "    for j, label in enumerate(labels):\n",
        "        if label in path:\n",
        "            labels_one_hot[i][j] = 1\n",
        "\n",
        "# 데이터 분할\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels_one_hot, test_size=0.3, random_state=42)\n",
        "\n",
        "# ResNet50 모델 생성\n",
        "base_model = ResNet50(weights='imagenet', include_top=False)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(labels), activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 미세 조정 (Fine-tuning) 설정\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    train_paths,\n",
        "    train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(test_paths, test_labels)\n",
        ")\n",
        "\n",
        "# 시각화를 통한 정확도 및 손실도 확인\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_acc = model.evaluate(test_paths, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "usfAM5JRUfHy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}